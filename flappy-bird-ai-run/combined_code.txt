-e 
# === File: ./game.js ===

//basic flappy bird **so its easier to train 



class GameEngine {
    constructor(canvas) {
      this.ctx = canvas.getContext('2d');
      this.reset();
    }
  
    reset() {
      this.bird = { x: 80, y: 300, vel: 0 };
      this.pipes = [];
      this.frameCount = 0;
      this.score = 0;
      this.done = false;
    }
  
    // returns state vector [birdY, birdVel, pipeXDist, pipeGapY]
    getState() {
      // find next pipe
      const nextPipe = this.pipes.find(p => p.x + p.width > this.bird.x) || this.pipes[0];
      return [
        this.bird.y / 600,
        this.bird.vel / 10,
        (nextPipe.x - this.bird.x) / 400,
        nextPipe.gapY / 600
      ];
    }
  
    flap() {
      this.bird.vel = -8;
    }
  
    step(action) {
      // apply action
      if (action === 1) this.flap();
  
      // physics
      this.bird.vel += 0.5;
      this.bird.y += this.bird.vel;
  
      // spawn pipes
      if (this.frameCount % 90 === 0) {
        const gapY = 150 + Math.random() * 200;
        this.pipes.push({ x: 400, gapY, width: 50, passed: false });
      }
      this.frameCount++;
  
      // move pipes & check for score/crash
      this.pipes.forEach(pipe => {
        pipe.x -= 2;
        if (!pipe.passed && pipe.x + pipe.width < this.bird.x) {
          this.score++;
          pipe.passed = true;
        }
      });
      // remove old
      this.pipes = this.pipes.filter(p => p.x > -p.width);
  
      // check collisions
      if (this.bird.y > 600 || this.bird.y < 0) this.done = true;
      this.pipes.forEach(p => {
        if (
          this.bird.x > p.x && this.bird.x < p.x + p.width &&
          (this.bird.y < p.gapY - 100 || this.bird.y > p.gapY)
        ) this.done = true;
      });
  
      // render
      this.render();
      
      
      //reward function 
      let reward = 0.1;  // small reward for surviving
      this.pipes.forEach(p => {
        if (!p.passed && p.x + p.width < this.bird.x) {
          this.score++;
          reward += 5;  // reward for passing pipe
          p.passed = true;
        }
      });
      if (this.done) reward = -100;



      return { state: this.getState(), reward, done: this.done };
    }
  
    render() {
      const ctx = this.ctx;
      ctx.clearRect(0, 0, 400, 600);
      // bird
      ctx.fillStyle = 'yellow';
      ctx.fillRect(this.bird.x, this.bird.y, 20, 20);
      // pipes
      ctx.fillStyle = 'green';
      this.pipes.forEach(p => {
        ctx.fillRect(p.x, 0, p.width, p.gapY - 100);
        ctx.fillRect(p.x, p.gapY, p.width, 600 - p.gapY);
      });
      // score
      ctx.fillStyle = 'white';
      ctx.font = '24px sans-serif';
      ctx.fillText(`Score: ${this.score}`, 10, 30);
    }
  }

  
  -e 
# === File: ./index.html ===

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Flappy Bird AI</title>
  <style>
    body { margin:0; background:#70c5ce; }
    canvas { display:block; margin:auto; background:#4ec0ca; }
  </style>
  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.20.0/dist/tf.min.js"></script>
</head>
<body>
  <canvas id="gameCanvas" width="400" height="600"></canvas>

  <!-- Your game and AI scripts -->
  <script src="./game.js"></script>
  <script src="./agent.js"></script>
  <script src="./main.js"></script>
</body>
</html>
-e 
# === File: ./main.js ===

// const canvas = document.getElementById('gameCanvas');
// const game = new GameEngine(canvas);

// //Custom Agent (You can change to use pre trained to better results)
// const agent = new DQNAgent(4, 2);

// async function trainEpisode() {
//   game.reset();
//   let { state, reward, done } = { state: game.getState(), reward: 0, done: false };
//   while (!done) {
//     const action = agent.act(state);
//     const stepResult = game.step(action);
//     agent.remember(state, action, stepResult.reward, stepResult.state, stepResult.done);
//     state = stepResult.state;
//     done = stepResult.done;
//     if (game.frameCount % 5 === 0 && agent.memory.length > 1000) {
//       await agent.replay(64);
//     }
//     await tf.nextFrame(); // yield to browser for rendering
//   }
// }

// // kick off training loop

// //50 Cycles
// (async function() {
//   for (let ep = 1; ep <= 50; ep++) {
//     await trainEpisode();
//     console.log(`Episode ${ep} complete — ε=${agent.epsilon.toFixed(2)} — score=${game.score}`);
//   }
//   console.log('Training complete! Now watch the AI play.');
  
//   await agent.model.save('file://./models/flappy-dqn');

//   // Here you could disable learning and let agent.act drive the rendering loop
// })();


-e 
# === File: ./train.js ===

// train.js
const tf = require('@tensorflow/tfjs');          // or '@tensorflow/tfjs-node'
const { GameEngine } = require('./game-env');
const { DQNAgent } = require('./agent');


//function for file save (workaround bc node tensor not supported yet )
const fs = require('fs');
const path = require('path');


//helper function save model to file 
async function saveModelToFile(model, dir) {
  if (!fs.existsSync(dir)) fs.mkdirSync(dir);
  const saveResult = await model.save({
    save: async function (modelArtifacts) {
      const modelJsonPath = path.join(dir, 'model.json');
      const weightsBinPath = path.join(dir, 'weights.bin');

      // Write JSON
      fs.writeFileSync(modelJsonPath, JSON.stringify({
        modelTopology: modelArtifacts.modelTopology,
        weightsManifest: [{
          paths: ['weights.bin'],
          weights: modelArtifacts.weightSpecs,
        }]
      }));
      

      // Write weights
      if (modelArtifacts.weightData) {
        fs.writeFileSync(weightsBinPath, Buffer.from(modelArtifacts.weightData));
      }

      return { modelArtifactsInfo: { dateSaved: new Date(), modelTopologyType: 'JSON' } };
    }
  });

  console.log(`✅ Model saved to ${dir}`);
}




//Getting trained Model 
async function loadModelFromFile(dir) {
  const modelJsonPath = path.join(dir, 'model.json');
  const weightsBinPath = path.join(dir, 'weights.bin');

  const model = await tf.loadLayersModel({
    load: async () => {
      const modelTopology = JSON.parse(fs.readFileSync(modelJsonPath));
      const weightData = fs.readFileSync(weightsBinPath);
      const weightSpecs = modelTopology.weightsManifest[0].weights;

      return {
        modelTopology: modelTopology.modelTopology,
        weightSpecs,
        weightData,
      };
    }
  });

  console.log('Model loaded from file!');
  return model;
}


async function getOrCreateAgent(stateSize, actionSize, modelPath) {
  const agent = new DQNAgent(stateSize, actionSize);

  const modelJsonPath = path.join(modelPath, 'model.json');
  const weightsBinPath = path.join(modelPath, 'weights.bin');

  if (fs.existsSync(modelJsonPath) && fs.existsSync(weightsBinPath)) {
    console.log('📦 Found saved model — loading...');
    console.log("TESTING")
    agent.model = await loadModelFromFile(modelPath);
    agent.epsilon = 0.05; // Lower exploration for inference
  } else {
    console.log('❌ No saved model found — training from scratch...');
    console.log("none found")
  }

  return agent;
}



(async () => {
  //Change depending on how many gen you want 

  const EPISODES = 100;
  const game = new GameEngine();
  
  
  // const agent = new DQNAgent(4, 2);
  const agent = await getOrCreateAgent(4, 2, './models/flappy-dqn'); //custom or pre trained 

  agent.model.compile({
    optimizer: 'adam',
    loss: 'meanSquaredError',
  });
  


  let bestScore = -Infinity;

  for (let ep = 1; ep <= EPISODES; ep++) {
    game.reset();
    let { state, reward, done } = {
      state: game.getState(),
      reward: 0,
      done: false
    };

    while (!done) {
      const action = agent.act(state);
      const { state: nextState, reward: r, done: d } = game.step(action);
      agent.remember(state, action, r, nextState, d);
      state = nextState;
      done = d;

      // Train every 5 frames once we have enough memory
      if (game.frameCount % 5 === 0 && agent.memory.length > 1000) {
        await agent.replay(64);
      }
    }

    // Update bestScore
    if (game.score > bestScore) {
      bestScore = game.score;
    }

    console.log(
      `Episode ${ep} complete — ε=${agent.epsilon.toFixed(2)} ` +
      `— score=${game.score}` +
      (game.score === bestScore ? ' ← new best!' : '')
    );

    // ─── AUTO‑CHECKPOINT ─────────────────────────────────────
    if (ep % 500 === 0) {
      console.log(`\n--- Auto‑checkpoint at episode ${ep} ---`);
      const ckptDir = `./models/checkpoint-${ep}`;
      await saveModelToFile(agent.model, ckptDir);
      fs.writeFileSync(
        './models/bestScore.json',
        JSON.stringify({ bestScore }, null, 2),
        'utf8'
      );
      console.log('✅ Auto‑checkpoint saved');
    }
    

  }

  console.log(`\n Training complete! Best score: ${bestScore}`);
  await saveModelToFile(agent.model, './models/flappy-dqn');

  process.exit(0);
})();-e 
# === File: ./agent.js ===

const tf = require('@tensorflow/tfjs');


class DQNAgent {
    constructor(stateSize, actionSize) {
      this.stateSize = stateSize;
      this.actionSize = actionSize;
      this.epsilon = 1.0;          // explore rate
      this.epsilonMin = 0.01;
      this.epsilonDecay = 0.995;
      this.gamma = 0.95;           // discount factor
      this.memory = [];
      this.buildModel();
    }
  
    buildModel() { //change from 24 -> 64 neurons
      
      this.model = tf.sequential();
      this.model.add(tf.layers.dense({ inputShape: [this.stateSize], units: 64, activation: 'relu' }));
      this.model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
      this.model.add(tf.layers.dense({ units: this.actionSize, activation: 'linear' }));
      this.model.compile({ optimizer: 'adam', loss: 'meanSquaredError' });
    }
      
    act(state) {
      if (Math.random() < this.epsilon) {
        return Math.floor(Math.random() * this.actionSize);
      }
      return tf.tidy(() => {
        const qs = this.model.predict(tf.tensor2d([state]));
        return qs.argMax(-1).dataSync()[0];
      });
    }
  
    remember(s, a, r, sNext, done) {
      this.memory.push({ s, a, r, sNext, done });
      if (this.memory.length > 50000) this.memory.shift();
    }
  
    async replay(batchSize = 32) {
      const sample = [];
      for (let i = 0; i < batchSize; i++) {
        sample.push(this.memory[Math.floor(Math.random() * this.memory.length)]);
      }
  
      const states = [];
      const targets = [];
  
      for (let { s, a, r, sNext, done } of sample) {
        const qsa = await tf.tidy(() => this.model.predict(tf.tensor2d([s])).arraySync()[0]);
        let target = r;
        if (!done) {
          const qNext = this.model.predict(tf.tensor2d([sNext])).max(-1).dataSync()[0];
          target = r + this.gamma * qNext;
        }
        qsa[a] = target;
        states.push(s);
        targets.push(qsa);
      }
  
      await this.model.fit(
        tf.tensor2d(states),
        tf.tensor2d(targets),
        { batchSize, epochs: 1, verbose: 0 }
      );
  
      if (this.epsilon > this.epsilonMin) {
        this.epsilon *= this.epsilonDecay;
      }
    }
  }

  

  module.exports = { DQNAgent };
 
-e 
# === File: ./game-env.js ===

// game-env.js
class GameEngine {
    constructor() {
      this.reset();
    }
  
    reset() {
      this.bird = { x: 80, y: 300, vel: 0 };
      this.pipes = [];
      this.frameCount = 0;
      this.score = 0;
      this.done = false;
    }
  
    getState() {
      const nextPipe = this.pipes.find(p => p.x + p.width > this.bird.x) || this.pipes[0] || { x: 400, gapY: 300, width: 50 };
      return [
        this.bird.y / 600,
        this.bird.vel / 10,
        (nextPipe.x - this.bird.x) / 400,
        nextPipe.gapY / 600
      ];
    }
  
    flap() {
      this.bird.vel = -8;
    }
  
    step(action) {
      if (action === 1) this.flap();
  
      // physics
      this.bird.vel += 0.5;
      this.bird.y += this.bird.vel;
  
      // spawn pipes every 90 frames
      if (this.frameCount % 90 === 0) {
        const gapY = 150 + Math.random() * 200;
        this.pipes.push({ x: 400, gapY, width: 50, passed: false });
      }
      this.frameCount++;
  
      // move pipes & score
      this.pipes.forEach(pipe => {
        pipe.x -= 2;
        if (!pipe.passed && pipe.x + pipe.width < this.bird.x) {
          this.score++;
          pipe.passed = true;
        }
      });
      this.pipes = this.pipes.filter(p => p.x > -p.width);
  
      // collisions
      if (this.bird.y > 600 || this.bird.y < 0) this.done = true;
      this.pipes.forEach(p => {
        if (
          this.bird.x > p.x &&
          this.bird.x < p.x + p.width &&
          (this.bird.y < p.gapY - 100 || this.bird.y > p.gapY)
        ) this.done = true;
      });
  
      const reward = this.done ? -100 : 1;
      return { state: this.getState(), reward, done: this.done };
    }
  }
  
  module.exports = { GameEngine };

  

  